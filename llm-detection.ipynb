{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7098714,"sourceType":"datasetVersion","datasetId":4091712}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load train and test datasets\ntrain_essays = pd.read_csv('/kaggle/input/llm-detection-dataset/train_essays.csv')\ntest_essays = pd.read_csv('/kaggle/input/llm-detection-dataset/test_essays.csv')\n\n# Preprocessing the data\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef preprocess_data(texts):\n    return tokenizer(\n        texts,\n        padding='max_length',\n        truncation=True,\n        max_length=512,\n        return_tensors='pt'\n    )\n\nclass EssaysDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        # Ensure labels are a list of integers\n        self.labels = labels if isinstance(labels, list) else labels.tolist()\n\n    def __getitem__(self, idx):\n        item = {key: val[idx].detach().clone() for key, val in self.encodings.items()}\n        # Convert integer label to a tensor of dtype long\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Preprocess and split the train dataset\nX_train, X_val, y_train, y_val = train_test_split(train_essays['text'], train_essays['generated'], test_size=0.2)\ntrain_encodings = preprocess_data(X_train.tolist())\nval_encodings = preprocess_data(X_val.tolist())\n\ntrain_dataset = EssaysDataset(train_encodings, y_train.tolist())\nval_dataset = EssaysDataset(val_encodings, y_val.tolist())\n\n# Load BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\n# Train the model\ntrainer.train()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T13:48:38.404657Z","iopub.execute_input":"2023-12-01T13:48:38.405440Z","iopub.status.idle":"2023-12-01T13:52:08.055212Z","shell.execute_reply.started":"2023-12-01T13:48:38.405405Z","shell.execute_reply":"2023-12-01T13:52:08.054301Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [207/207 02:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.511600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.436600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.342600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.245000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.169000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.079500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.037200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.061800</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.010800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.007200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.005100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.003800</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.003100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.002100</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.039700</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.028200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.002300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\ntrainer.evaluate()\n\n# Preprocess the test dataset\ntest_encodings = preprocess_data(test_essays['text'].tolist())\ntest_dataset = EssaysDataset(test_encodings, torch.zeros(len(test_essays), dtype=torch.long))\n# Predictions\npredictions = trainer.predict(test_dataset)\n\n# Convert predictions to binary labels\npred_labels = predictions.predictions.argmax(axis=-1)\n\n# Prepare the submission file\nsubmission = test_essays[['id']].copy()\nsubmission['generated'] = pred_labels\n\n# Save submission file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T13:53:33.398719Z","iopub.execute_input":"2023-12-01T13:53:33.399095Z","iopub.status.idle":"2023-12-01T13:53:38.065590Z","shell.execute_reply.started":"2023-12-01T13:53:33.399065Z","shell.execute_reply":"2023-12-01T13:53:38.064520Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}